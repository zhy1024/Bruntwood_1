{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81613398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pytesseract\n",
    "# !pip install PyPDF2\n",
    "# !apt install tesseract-ocr\n",
    "# !pip install pytesseract pdf2image\n",
    "# !apt update\n",
    "# !apt install poppler-utils\n",
    "# !pip install pdf2image\n",
    "# !pip install stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bf4276d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import re\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox, ttk, PhotoImage\n",
    "from pdf2image import convert_from_path\n",
    "from ttkthemes import ThemedTk, ThemedStyle\n",
    "from tkinter.ttk import Progressbar, Style\n",
    "import pytesseract\n",
    "import atexit\n",
    "import os\n",
    "import stanza\n",
    "import dateparser\n",
    "import csv\n",
    "from PIL import Image, ImageTk\n",
    "import datefinder\n",
    "import Quartz\n",
    "import Vision\n",
    "from Cocoa import NSURL\n",
    "from Foundation import NSDictionary\n",
    "# needed to capture system-level stderr\n",
    "from wurlitzer import pipes\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fe75f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = '/usr/local/bin/tesseract'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "008bded6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Use Apple's Vision Framework via PyObjC to detect text in images \"\"\"\n",
    "\n",
    "\n",
    "def image_to_text(img_path, lang=\"eng\"):\n",
    "    input_url = NSURL.fileURLWithPath_(img_path)\n",
    "\n",
    "    with pipes() as (out, err):\n",
    "    # capture stdout and stderr from system calls\n",
    "    # otherwise, Quartz.CIImage.imageWithContentsOfURL_\n",
    "    # prints to stderr something like:\n",
    "    # 2020-09-20 20:55:25.538 python[73042:5650492] Creating client/daemon connection: B8FE995E-3F27-47F4-9FA8-559C615FD774\n",
    "    # 2020-09-20 20:55:25.652 python[73042:5650492] Got the query meta data reply for: com.apple.MobileAsset.RawCamera.Camera, response: 0\n",
    "        input_image = Quartz.CIImage.imageWithContentsOfURL_(input_url)\n",
    "\n",
    "    vision_options = NSDictionary.dictionaryWithDictionary_({})\n",
    "    vision_handler = Vision.VNImageRequestHandler.alloc().initWithCIImage_options_(\n",
    "        input_image, vision_options\n",
    "    )\n",
    "    results = []\n",
    "    handler = make_request_handler(results)\n",
    "    vision_request = Vision.VNRecognizeTextRequest.alloc().initWithCompletionHandler_(handler)\n",
    "    error = vision_handler.performRequests_error_([vision_request], None)\n",
    "\n",
    "    return results\n",
    "\n",
    "def make_request_handler(results):\n",
    "    \"\"\" results: list to store results \"\"\"\n",
    "    if not isinstance(results, list):\n",
    "        raise ValueError(\"results must be a list\")\n",
    "\n",
    "    def handler(request, error):\n",
    "        if error:\n",
    "            print(f\"Error! {error}\")\n",
    "        else:\n",
    "            observations = request.results()\n",
    "            for text_observation in observations:\n",
    "                recognized_text = text_observation.topCandidates_(1)[0]\n",
    "                results.append([recognized_text.string(), recognized_text.confidence()])\n",
    "    return handler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "385870ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextExtractor:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title('Choose File')\n",
    "        self.image = Image.open(\"Bruntwood_icon.png\")\n",
    "        # Convert the image to a Tkinter-compatible format\n",
    "        self.root.iconphoto(True, ImageTk.PhotoImage(self.image))\n",
    "        self.root.geometry('400x200')\n",
    "        self.extractor = Extractor()  # Create RentExtractor instance\n",
    "        self.choose_file_page = ChooseFilePage(self.root, self.extractor)\n",
    "        self.choose_file_page.setup_close_handler(self)  # Pass the TextExtractor instance to handle the closure\n",
    "        \n",
    "    def on_closing(self):\n",
    "        # Custom function to handle the window closure\n",
    "        if hasattr(self, \"choose_file_page\") and hasattr(self.choose_file_page, \"display_text_page\"):\n",
    "            self.choose_file_page.display_text_page.destroy()  # Destroy the DisplayTextPage if it exists\n",
    "        self.root.destroy()  # Close the main application window\n",
    "        os._exit(0)\n",
    "#         root.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce8a9a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Extractor:\n",
    "    def __init__(self):\n",
    "        self.nlp = spacy.load('en_core_web_sm')\n",
    "        self.stanza_nlp = stanza.Pipeline(processors='tokenize,ner', lang='en')\n",
    "        self.matcher = Matcher(self.nlp.vocab)\n",
    "        self.match_after = Matcher(self.nlp.vocab)\n",
    "        self.match_before = Matcher(self.nlp.vocab)\n",
    "        self.match_term = Matcher(self.nlp.vocab)\n",
    "        self.info = {}\n",
    "        self.initialize_matchers()\n",
    "\n",
    "    def initialize_matchers(self):\n",
    "        # Define the first search patterns\n",
    "        rent_value_pattern = [\n",
    "            {\"LOWER\": {\"IN\": [\"annual\", \"initial\"]}, \"OP\": \"?\"},\n",
    "            {\"LOWER\": \"rent\"}\n",
    "        ]\n",
    "        term_pattern = [{\"LOWER\": \"term\"}]\n",
    "        commencement_date_pattern = [{\"LOWER\": \"term\"}, {\"LOWER\": \"commencement\"}, {\"LOWER\": \"date\"}]\n",
    "        review_date_pattern = [{\"LOWER\": \"review\"},{\"LOWER\":{\"IN\":[\"date\", \"date(s\"]}}]\n",
    "        lease_date_pattern = [{\"LOWER\": \"date\"}, {\"LOWER\": \"of\"}, {\"LOWER\": \"lease\"}]\n",
    "        lease_date_pattern_2 = [{\"LOWER\": \"dated\"}]\n",
    "        customer_break_date_pattern = [{\"LOWER\": {\"IN\":[\"customer\",\"tenant\"]}}, {\"LOWER\": \"break\"}, {\"LOWER\":\"date\", \"OP\":\"?\"}]\n",
    "        \n",
    "        \n",
    "        # Add the patterns to the matcher\n",
    "        self.matcher.add(\"RENT_VALUE\", [rent_value_pattern])\n",
    "        self.matcher.add(\"TERM\", [term_pattern])\n",
    "        self.matcher.add(\"COMMENCEMENT_DATE\", [commencement_date_pattern])\n",
    "        self.matcher.add(\"REVIEW_DATE\", [review_date_pattern])\n",
    "        self.matcher.add(\"LEASE_DATE\", [lease_date_pattern])\n",
    "        self.matcher.add(\"LEASE_DATE_2\", [lease_date_pattern_2])\n",
    "        self.matcher.add(\"CUSTOMER_BREAK_DATE\", [customer_break_date_pattern])\n",
    "        \n",
    "        rent_after_pattern = rent_value_pattern +[\n",
    "             {\"OP\": \"*\"},\n",
    "             {\"LOWER\": {\"IN\": [\"£\", \"$\", \"€\"]}},\n",
    "             {\"TEXT\": {\"REGEX\": r\"[\\d,.]+\"}}]\n",
    "\n",
    "        rent_before_pattern =[{\"LOWER\": {\"IN\": [\"£\", \"$\", \"€\"]}},\n",
    "                     {\"TEXT\": {\"REGEX\": r\"[\\d,.]+\"}},\n",
    "                     {\"OP\": \"*\"}] + rent_value_pattern\n",
    "\n",
    "        self.match_after.add(\"rent_after\",[rent_after_pattern])\n",
    "        self.match_before.add(\"rent_after\",[rent_before_pattern])\n",
    "\n",
    "        # works for x years, x (x) years... with spaces.\n",
    "        term_length_pattern = [\n",
    "            {\"LIKE_NUM\": True, \"OP\": \"+\"},\n",
    "            {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "            {\"IS_PUNCT\": True, \"OP\":\"?\"},\n",
    "            {\"LIKE_NUM\": True, \"OP\":\"?\"},\n",
    "            {\"IS_PUNCT\": True, \"OP\":\"?\"},\n",
    "            {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "            {\"LOWER\": {\"IN\": [\"year\", \"years\"]}}\n",
    "        ]\n",
    "\n",
    "        self.match_term.add(\"TERM_LENGTH\", [term_length_pattern])\n",
    "\n",
    "    def extract_info(self, text):\n",
    "        doc = self.nlp(text)\n",
    "        rent = None\n",
    "        term_length = None\n",
    "        commencement_date = None\n",
    "        review_date = None\n",
    "        lease_date = None\n",
    "        customer_break_date = None\n",
    "        \n",
    "        matches = self.matcher(doc)\n",
    "\n",
    "        # Extract and print the matched spans\n",
    "        for match_id, start, end in matches:\n",
    "            if self.nlp.vocab.strings[match_id] == \"RENT_VALUE\":\n",
    "                if rent:\n",
    "                    continue\n",
    "                else:\n",
    "                    rent = self.second_match(self.match_after, doc,start,min(end+200,len(doc)),r'[£$€][\\d,.]+')\n",
    "                    if rent:\n",
    "                        continue\n",
    "                    else:\n",
    "                        rent = self.second_match(self.match_before, doc,max(start-15,0),end,r'[£$€][\\d,.]+')\n",
    "            elif self.nlp.vocab.strings[match_id] == \"TERM\":\n",
    "                if term_length:\n",
    "                    continue\n",
    "                else:\n",
    "                    span = doc[start: min(end+20,len(doc))]\n",
    "                    matches_terms = self.match_term(span)\n",
    "                    for term_id, start_t, end_t in matches_terms:\n",
    "                        term_length = span[start_t:end_t].text\n",
    "\n",
    "            elif self.nlp.vocab.strings[match_id] == \"COMMENCEMENT_DATE\":\n",
    "#                 if doc[start-2: start-1].text.lower() in [\"include\", \"including\", \"from\", \"to\"] and doc[start-1: start].text.lower() in [\"the\"]:\n",
    "#                     continue\n",
    "#                 else:\n",
    "                if commencement_date:\n",
    "                    continue\n",
    "                else:\n",
    "                    commencement_date = self.extract_dates_with_sutime_and_dateparser(doc[start:end +25].text)\n",
    "            \n",
    "            elif self.nlp.vocab.strings[match_id] == \"REVIEW_DATE\":\n",
    "                if review_date:\n",
    "                    continue\n",
    "                else:\n",
    "#                     if doc[start+1: start+2] == \"date(s\":\n",
    "#                         review_date = []\n",
    "#                         review_date.append(self.extract_dates_with_sutime_and_dateparser(doc[start:end +50].text))\n",
    "#                         review_date.append(self.extract_dates_with_sutime_and_dateparser(doc[start+10:end +50].text))\n",
    "#                     else:\n",
    "                        review_date = self.extract_dates_with_sutime_and_dateparser(doc[start:end +15].text)\n",
    "                    \n",
    "            elif self.nlp.vocab.strings[match_id] == \"LEASE_DATE\":\n",
    "                if lease_date:\n",
    "                    continue\n",
    "                else:\n",
    "                    lease_date = self.extract_dates_with_sutime_and_dateparser(doc[start-8:end +15].text)\n",
    "                    \n",
    "            elif self.nlp.vocab.strings[match_id] == \"LEASE_DATE_2\":\n",
    "                if lease_date:\n",
    "                    continue\n",
    "                else:\n",
    "                    lease_date = self.extract_dates_with_sutime_and_dateparser(doc[start:end +15].text)\n",
    "                \n",
    "            elif self.nlp.vocab.strings[match_id] == \"CUSTOMER_BREAK_DATE\":\n",
    "                if customer_break_date:\n",
    "                    continue\n",
    "                else:\n",
    "                    customer_break_date = self.extract_dates_with_sutime_and_dateparser(doc[start:end +15].text)\n",
    "\n",
    "\n",
    "        self.info['Date of Lease'] = lease_date\n",
    "        self.info['Annual Rent']= rent\n",
    "        self.info['Term']= term_length\n",
    "        self.info['Term Commencement Date'] = commencement_date\n",
    "        self.info['Review Date'] = review_date\n",
    "        self.info['Customer Break Date'] = customer_break_date\n",
    "        \n",
    "        return self.info\n",
    "\n",
    "    \n",
    "    def second_match(self, match_func, doc, start, end, reg_pattern):\n",
    "        res = None\n",
    "        span = doc[start: end]\n",
    "\n",
    "        res_matched = match_func(span)\n",
    "        if res_matched:\n",
    "            res = re.search(reg_pattern, span.text).group()\n",
    "        return res\n",
    "\n",
    "    \n",
    "    def extract_dates_with_sutime_and_dateparser(self, text):\n",
    "#         self.nlp = stanza.Pipeline(processors='tokenize,ner', lang='en')\n",
    "        processed_text = re.sub(r'(\\d+)\"', r'\\1', text)\n",
    "        doc = self.stanza_nlp(processed_text)\n",
    " \n",
    "        dates = []\n",
    "        for sentence in doc.sentences:\n",
    "            for entity in sentence.ents:\n",
    "                if entity.type == 'DATE':\n",
    "                    if not any(indicator in entity.text.lower().split() for indicator in [\"days\", \"date\",\"day\",\"year\",\"years\",\"month\",\"months\", \"daily\",\"bruntwood\"]):\n",
    "                        dates.append(entity.text)\n",
    "\n",
    "        # If SUTime extracted any dates, return the first one\n",
    "        if dates:\n",
    "            dates = [date.replace(\"\\n\", \" \") for date in dates]\n",
    "            dates = self.filter_dates_with_datefinder(dates)\n",
    "            if dates:\n",
    "                return dates.strftime('%d-%m-%Y')\n",
    "\n",
    "\n",
    "        datefinder_dates = list(datefinder.find_dates(text, strict = True))\n",
    "\n",
    "\n",
    "        if datefinder_dates:\n",
    "            return datefinder_dates[0].strftime('%d-%m-%Y')\n",
    "\n",
    "        return None\n",
    "\n",
    "    def filter_dates_with_datefinder(self, dates):\n",
    "        for date_string in dates:\n",
    "            parsed_dates = list(datefinder.find_dates(date_string))\n",
    "            if parsed_dates:\n",
    "                return parsed_dates[0]\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20834e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChooseFilePage(tk.Frame):\n",
    "    def __init__(self, root, extractor):\n",
    "        super().__init__(root)\n",
    "        self.style = Style()\n",
    "        self.style.theme_use('adapta')\n",
    "        self.root = root\n",
    "        self.extractor = extractor  # Store the RentExtractor instance\n",
    "        self.pack(fill=tk.BOTH, expand=True)\n",
    "        self.pack_propagate(False)\n",
    "\n",
    "        self.file_label = tk.Label(self, text=\"  \", font=(\"Arial\", 16))\n",
    "        self.file_label.pack()\n",
    "        \n",
    "        self.logo = Image.open(\"Logo-bruntwood.png\")\n",
    "        self.logo = self.logo.resize((100, 50), Image.ANTIALIAS)\n",
    "        self.tk_logo = ImageTk.PhotoImage(self.logo)\n",
    "        \n",
    "        # Create a Label widget for the image and place it using grid\n",
    "        self.image_label = tk.Label(root, image=self.tk_logo)\n",
    "        self.image_label.pack(anchor = \"se\")\n",
    "#         self.image_label.pack(side = tk.TOP, padx=10, pady=10)  # Adjust padx, pady as needed\n",
    "\n",
    "        self.choose_file = tk.Button(self, text=\"Choose File\", width = 10,height = 3, command=self.open_file_dialog)\n",
    "        self.choose_file.pack(pady=(50, 0), side = tk.LEFT, padx=10)\n",
    "\n",
    "        self.extract_btn = tk.Button(self, text=\"Extract\", width = 10,height =3, command=self.show_extracted_text)\n",
    "        self.file_path = None\n",
    "\n",
    "    def open_file_dialog(self):\n",
    "        self.file_path = filedialog.askopenfilename()\n",
    "        if self.file_path:\n",
    "            self.file_label.config(text=f\"File path: {self.file_path}\", wraplength=self.winfo_width())\n",
    "            messagebox.showinfo(\"Import file successfully!\", f\"{self.file_path} imported successfully!\")\n",
    "            self.extract_btn.pack(pady= (50,0), side = tk.LEFT, padx= 0)\n",
    "        else:\n",
    "            messagebox.showinfo(\"No file selected\", \"No file selected!\")\n",
    "\n",
    "    def show_extracted_text(self):\n",
    "        threading.Thread(target=self.extract_text_display).start()\n",
    "\n",
    "\n",
    "    def extract_text_display(self):\n",
    "        progress_window = tk.Toplevel(self.root)\n",
    "        progress_window.title(\"Text Extraction Progress\")\n",
    "        progress_window.geometry(\"300x100\")\n",
    "        progress_window.resizable(False, False)\n",
    "\n",
    "        progress_label = tk.Label(progress_window, text=\"Extracting text...\", font=(\"Arial\", 12))\n",
    "        progress_label.pack(pady=10)\n",
    "\n",
    "        self.progress_bar = Progressbar(progress_window, orient=tk.HORIZONTAL, length=200, mode='determinate')\n",
    "        self.progress_bar.pack(pady=5)\n",
    "\n",
    "        self.percentage_label = tk.Label(progress_window, text=\"0% extracted\")\n",
    "        self.percentage_label.pack(pady=5)\n",
    "\n",
    "        extracted_text = self.extract_text_from_pdf(self.file_path)\n",
    "\n",
    "        info = self.extractor.extract_info(extracted_text)\n",
    "\n",
    "        progress_window.destroy()\n",
    "\n",
    "        # Now, only pass the extracted rent to the DisplayTextPage\n",
    "        DisplayTextPage(self.root, self.file_path, info, extracted_text)  # Pass extracted_text as well\n",
    "\n",
    "        # Destroy the current page (ChooseFilePage)\n",
    "        self.destroy()\n",
    "\n",
    "\n",
    "    def extract_text_from_pdf(self, pdf_path):\n",
    "        start = time.time()\n",
    "        images = convert_from_path(pdf_path)\n",
    "        text = \"\"\n",
    "        total_images = len(images)\n",
    "\n",
    "        for idx, image in enumerate(images, 1):\n",
    "\n",
    "#             image.save('image.png')\n",
    "#             text_list = image_to_text('image.png')\n",
    "#             formatted_text = \"\\n\".join([item[0] for item in text_list])\n",
    "#             text+= formatted_text\n",
    "#             os.remove('image.png')\n",
    "            image_bytes = image.convert(\"RGB\")\n",
    "            text += pytesseract.image_to_string(image_bytes, lang='eng')\n",
    "\n",
    "\n",
    "            # Update the progress bar with the percentage of extracted work\n",
    "            percentage = (idx / total_images) * 100\n",
    "            self.update_progress_bar(percentage)\n",
    "            self.percentage_label.config(text=f\"{int(percentage)}% extracted\")\n",
    "            self.progress_bar.update_idletasks()\n",
    "        end = time.time()\n",
    "        \n",
    "        runtime = end - start\n",
    "        print(runtime)\n",
    "        \n",
    "        return text\n",
    "\n",
    "    def update_progress_bar(self, percentage):\n",
    "        self.progress_bar[\"value\"] = percentage\n",
    "        self.root.update_idletasks()\n",
    "\n",
    "            \n",
    "    def setup_close_handler(self, text_extractor):\n",
    "        # Register the cleanup function to be called when the program exits\n",
    "        self.root.protocol(\"WM_DELETE_WINDOW\", lambda: text_extractor.on_closing())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fb20447",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisplayTextPage:\n",
    "    def __init__(self, root, file_path, extracted_info, original_text):\n",
    "        self.root = root\n",
    "        self.root.title('Extracted Info')\n",
    "        self.root.geometry('600x400')\n",
    "        self.file_path = file_path \n",
    "        self.file_name = os.path.split(self.file_path)[-1]\n",
    "        self.extractor = Extractor()\n",
    "\n",
    "        file_label = tk.Label(self.root, text=f\"File name: {self.file_name}\", font=(\"Arial\", 14), wraplength=580)\n",
    "        file_label.pack(pady=10, padx=10, anchor=tk.W, fill=tk.X, expand=True)\n",
    "\n",
    "        extracted_info_frame = tk.Frame(self.root)\n",
    "        extracted_info_frame.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        columns = (\"Key\", \"Value\")\n",
    "        self.treeview = ttk.Treeview(extracted_info_frame, columns=columns, show=\"headings\", height=5)\n",
    "        self.treeview.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        self.treeview.heading(\"Key\", text=\" \")\n",
    "        self.treeview.heading(\"Value\", text=\"Value\")\n",
    "\n",
    "        for key, value in extracted_info.items():\n",
    "            self.treeview.insert(\"\", tk.END, values=(key, value))\n",
    "\n",
    "        export_csv_btn = tk.Button(extracted_info_frame, text=\"Export CSV\", command=self.export_to_csv)\n",
    "        export_csv_btn.pack(pady=10, padx=10, side=tk.LEFT)\n",
    "\n",
    "        export_txt_btn = tk.Button(extracted_info_frame, text=\"Export TXT\", command=lambda: self.export_to_txt(original_text))\n",
    "        export_txt_btn.pack(pady=10, padx=10, side=tk.LEFT)\n",
    "        \n",
    "        extract_next_btn = tk.Button(extracted_info_frame, text=\"Extract next file\", command=self.go_to_choose_file)\n",
    "        extract_next_btn.pack(pady=10, padx=10, side=tk.LEFT)\n",
    "        \n",
    "        \n",
    "    def export_to_csv(self):\n",
    "        origin_filename = os.path.split(self.file_path)[-1]\n",
    "\n",
    "        # Get the user's chosen file path for saving CSV\n",
    "        file_path = filedialog.asksaveasfilename(defaultextension=\".csv\", filetypes=[(\"CSV Files\", \"*.csv\")])\n",
    "        \n",
    "        if file_path:\n",
    "            filename = os.path.basename(file_path)\n",
    "\n",
    "            with open(filename, mode=\"w\", newline=\"\") as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow([\"Key\", \"Value\"])  # Writing the header\n",
    "                for item in self.treeview.get_children():\n",
    "                    key = self.treeview.item(item, \"values\")[0]\n",
    "                    value = self.treeview.item(item, \"values\")[1]\n",
    "                    writer.writerow([key, value])\n",
    "\n",
    "            tk.messagebox.showinfo(\"CSV Export\", f\"{origin_filename} data has been exported to {file_path}\")\n",
    "\n",
    "\n",
    "        \n",
    "    def export_to_txt(self, original_text):\n",
    "        origin_filename = os.path.split(self.file_path)[-1] \n",
    "\n",
    "        # Get the user's chosen file path\n",
    "        file_path = filedialog.asksaveasfilename(defaultextension=\".txt\", filetypes=[(\"Text Files\", \"*.txt\")])\n",
    "        \n",
    "        if file_path:\n",
    "            filename = os.path.basename(file_path)\n",
    "\n",
    "            with open(file_path, 'w') as txt_file:\n",
    "                txt_file.write(original_text)\n",
    "\n",
    "            tk.messagebox.showinfo(\"TXT Export\", f\"{origin_filename} has been exported to {file_path}\")\n",
    "        \n",
    "    def go_to_choose_file(self):\n",
    "        # Destroy the current page (DisplayTextPage)\n",
    "        self.root.destroy()\n",
    "\n",
    "        # Recreate the ChooseFilePage\n",
    "        self.root = ThemedTk(theme=\"adapta\")  # Create a new root window\n",
    "        app = TextExtractor(self.root)\n",
    "        self.root.protocol(\"WM_DELETE_WINDOW\", app.on_closing)\n",
    "        self.root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd0c1bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-30 01:13:06 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9c9fab2a8b44d73aa59e94fc39c1f85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-30 01:13:07 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | combined  |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2023-08-30 01:13:07 INFO: Using device: cpu\n",
      "2023-08-30 01:13:07 INFO: Loading: tokenize\n",
      "2023-08-30 01:13:07 INFO: Loading: ner\n",
      "2023-08-30 01:13:07 INFO: Done loading processors!\n",
      "/var/folders/fy/d4f6hj590s3fltpf_56_nl_40000gn/T/ipykernel_28388/3237724039.py:15: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  self.logo = self.logo.resize((100, 50), Image.ANTIALIAS)\n",
      "2023-08-30 01:13:09.922 python[28388:12818022] +[CATransaction synchronize] called within transaction\n",
      "2023-08-30 01:13:23.970 python[28388:12818022] +[CATransaction synchronize] called within transaction\n",
      "2023-08-30 01:13:27.804 python[28388:12818022] +[CATransaction synchronize] called within transaction\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.15282273292542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-30 01:15:05 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "660390ce1ef84bc4a6c7476ffcc2a823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-30 01:15:06 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | combined  |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2023-08-30 01:15:06 INFO: Using device: cpu\n",
      "2023-08-30 01:15:06 INFO: Loading: tokenize\n",
      "2023-08-30 01:15:06 INFO: Loading: ner\n",
      "2023-08-30 01:15:06 INFO: Done loading processors!\n",
      "2023-08-30 01:22:47.968 python[28388:12818022] +[CATransaction synchronize] called within transaction\n",
      "2023-08-30 01:40:29.894 python[28388:12818022] +[CATransaction synchronize] called within transaction\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = ThemedTk(theme=\"adapta\")\n",
    "    TextExtractor(root)\n",
    "    root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
