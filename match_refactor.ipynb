{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "a6a0ae02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "import re\n",
    "import stanza\n",
    "import dateparser\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "34702627",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'extracted_text.txt'\n",
    "file = open(file_path, 'r')\n",
    "\n",
    "# Read the entire file content\n",
    "text = file.read()\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "4054c968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the spaCy English model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Process the text using spaCy\n",
    "doc = nlp(text)\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "info = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "03e435c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when key words match, find the info by regex. match_func is the new matcher for specific rule\n",
    "# doc is whole doc, reg_pattern is the patter for result\n",
    "def second_match(match_func, doc, start, end, reg_pattern):\n",
    "    res = None\n",
    "    span = doc[start: end]\n",
    "    \n",
    "    res_matched = match_func(span)\n",
    "    if res_matched:\n",
    "        res = re.search(reg_pattern, span.text).group()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "23fe9f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the first search patterns\n",
    "rent_value_pattern = [\n",
    "    {\"LOWER\": {\"IN\": [\"annual\", \"initial\"]}, \"OP\": \"?\"},\n",
    "    {\"LOWER\": \"rent\"}\n",
    "]\n",
    "term_pattern = [{\"LOWER\": \"term\"}]\n",
    "commencement_date_pattern = [{\"LOWER\": \"term\"}, {\"LOWER\": \"commencement\"}, {\"LOWER\": \"date\"}]\n",
    "\n",
    "# Add the patterns to the matcher\n",
    "matcher.add(\"RENT_VALUE\", [rent_value_pattern])\n",
    "matcher.add(\"TERM\", [term_pattern])\n",
    "matcher.add(\"COMMENCEMENT_DATE\", [commencement_date_pattern])\n",
    "\n",
    "# Find matches in the text\n",
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "28377564",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for match rent\n",
    "match_rent_after = Matcher(nlp.vocab)\n",
    "\n",
    "match_rent_before = Matcher(nlp.vocab)\n",
    "\n",
    "rent_after_pattern = rent_value_pattern +[\n",
    "             {\"OP\": \"*\"},\n",
    "             {\"LOWER\": {\"IN\": [\"£\", \"$\", \"€\"]}},\n",
    "             {\"TEXT\": {\"REGEX\": r\"[\\d,.]+\"}}]\n",
    "\n",
    "rent_before_pattern =[{\"OP\": \"*\"},\n",
    "             {\"LOWER\": {\"IN\": [\"£\", \"$\", \"€\"]}},\n",
    "             {\"TEXT\": {\"REGEX\": r\"[\\d,.]+\"}}] + rent_value_pattern\n",
    "\n",
    "match_rent_after.add(\"rent_after\",[rent_after_pattern])\n",
    "match_rent_before.add(\"rent_after\",[rent_before_pattern])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "bea7616e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for match term\n",
    "match_term = Matcher(nlp.vocab)\n",
    "\n",
    "# works for x years, x (x) years... with spaces.\n",
    "term_length_pattern = [\n",
    "    {\"LIKE_NUM\": True, \"OP\": \"+\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"IS_PUNCT\": True, \"OP\":\"?\"},\n",
    "    {\"LIKE_NUM\": True, \"OP\":\"?\"},\n",
    "    {\"IS_PUNCT\": True, \"OP\":\"?\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"LOWER\": {\"IN\": [\"year\", \"years\", \"month\", \"months\"]}}\n",
    "]\n",
    "\n",
    "match_term.add(\"TERM_LENGTH\", [term_length_pattern])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "de8161af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dates_with_sutime_and_dateparser(text):\n",
    "    nlp = stanza.Pipeline(processors='tokenize,ner', lang='en')\n",
    "    doc = nlp(text)\n",
    "\n",
    "    dates = []\n",
    "    for sentence in doc.sentences:\n",
    "        for entity in sentence.ents:\n",
    "            if entity.type == 'DATE':\n",
    "                dates.append(entity.text)\n",
    "\n",
    "    # If SUTime extracted any dates, return the first one\n",
    "    if dates:\n",
    "        return [dates[0].replace('\\n', ' ')]\n",
    "\n",
    "    # If no dates were extracted by SUTime, try using dateparser\n",
    "    parsed_dates = dateparser.parse(text, settings={'STRICT_PARSING': False})\n",
    "    if parsed_dates:\n",
    "        return [parsed_dates[0].strftime('%Y-%m-%d')]\n",
    "\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "823d5d4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-03 09:51:48 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ede27fc9db974e8e86373863a79066de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-03 09:51:49 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | combined  |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2023-08-03 09:51:49 INFO: Using device: cpu\n",
      "2023-08-03 09:51:49 INFO: Loading: tokenize\n",
      "2023-08-03 09:51:49 INFO: Loading: ner\n",
      "2023-08-03 09:51:50 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Annual Rent': '£15,625', 'Term': 'ten (10) years', 'Term Commencement Date': ['24 December 2016']}\n"
     ]
    }
   ],
   "source": [
    "rent = None\n",
    "term_length = None\n",
    "commencement_date = None\n",
    "\n",
    "# Extract and print the matched spans\n",
    "for match_id, start, end in matches:\n",
    "#     matched_text = doc[start:end].text\n",
    "    if nlp.vocab.strings[match_id] == \"RENT_VALUE\":\n",
    "        if rent:\n",
    "            continue\n",
    "        else:\n",
    "            rent = second_match(match_rent_after, doc,start,min(end+50,len(doc)),r'[£$€][\\d,.]+')\n",
    "            if rent:\n",
    "                continue\n",
    "            else:\n",
    "                rent = second_match(match_rent_before, doc,max(start-15,0),end,r'[£$€][\\d,.]+')\n",
    "    elif nlp.vocab.strings[match_id] == \"TERM\":\n",
    "        if term_length:\n",
    "            continue\n",
    "        else:\n",
    "            span = doc[start: min(end+20,len(doc))]\n",
    "            matches_terms = match_term(span)\n",
    "            for term_id, start_t, end_t in matches_terms:\n",
    "                term_length = span[start_t:end_t].text\n",
    "\n",
    "    elif nlp.vocab.strings[match_id] == \"COMMENCEMENT_DATE\":\n",
    "        if commencement_date:\n",
    "            continue\n",
    "        else:\n",
    "            commencement_date = extract_dates_with_sutime_and_dateparser(doc[start:end +25].text)\n",
    "\n",
    "info['Annual Rent']= rent\n",
    "info['Term']= term_length\n",
    "info['Term Commencement Date'] = commencement_date\n",
    "print(info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
